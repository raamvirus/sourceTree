/*apply schema to a specific RDD */
package com.spark.pkg

import org.apache.spark.SparkContext
import org.apache.spark.sql.SQLContext
import org.apache.spark.sql.api.java.JavaSparkContext;
import org.apache.spark.sql.Row;
import org.apache.spark.sql.types.{StructType,StructField,StringType};
import  org.apache.spark.sql.types.IntegerType


object SQLMain2 extends App{
  val rdd : RDD[Row] = sc.parallelize(List(("raam",32),("Me",1)))
      .map {case(name,count) => Row(name,count) }

val schema = StructType(List(
      StructField("name",StringType,nullable=false),
      StructField("value",IntegerType,false)
      ))
val df = sqlContext.createDataFrame(rdd,schema)
df.printSchema()
//--------------------------------------------------------------//
df.registerTempTable("authors")
val authorDF = sqlContext.sql(
  """
     |SELECT * FROM authors WHERE value >0
  """.stripMargin)
authorsDF.show()
//--------------------------------------------------------------//
}



root
 |-- name: string (nullable = false)
 |-- nbBooks: integer (nullable = false)


name  value
raam  32
Me  1

*/